{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1b03255-b12c-4f77-a08b-515159291ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mediapipe opencv-python pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5d0bb15-1f9c-4bfb-b064-2d7900450cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose #this is where we are importing the pre-built pose detection model from mediapipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a817ae6-5241-4ffa-9330-4d4554795302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# Define the HTML content\n",
    "html_content = '<image src=\"https://i.imageur.com/3j8BPdc.png\" style=\"height:300px\">'\n",
    "\n",
    "# Display the HTML content\n",
    "display(HTML(html_content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e41a741-0476-41fe-8b7b-3ae25b8ec9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a488f6bc-c4b2-4c0e-9a33-045e29ceb23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "landmarks = ['class']\n",
    "for val in range(1, 34): #because 33 points\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03c7a2cb-8409-47f1-b9a9-65778a119076",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1d90ae2-7040-4061-aefd-5b9c7fbf9b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coords.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar= '\"', quoting= csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "741204b6-8fa3-4eb2-809e-100f033060dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_landmark(results, action):\n",
    "    try:\n",
    "        keypoints = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten()\n",
    "        keypoints = np.insert(keypoints, 0, action)  # Insert action at the beginning\n",
    "\n",
    "        with open('coords.csv', mode='a', newline='') as f:\n",
    "            csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            csv_writer.writerow(keypoints)\n",
    "    except Exception as e:\n",
    "        print('Error occurred while exporting landmarks:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e5f7d46-a5d9-4e28-a02b-5e359a4a310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#video feed\n",
    "cap = cv2.VideoCapture('squats.mp4') #this number is the number of my web cam\n",
    "\n",
    "#setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read() \n",
    "        \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) \n",
    "        image.flags.writeable = False #save a bunch of memory\n",
    "\n",
    "        #make detections from the pose\n",
    "        results = pose.process(image) #by processing it, we get our detections back\n",
    "    \n",
    "        #back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "       \n",
    "        k = cv2.waitKey(1)\n",
    "        if k == 117:\n",
    "            export_landmark(results, '1')\n",
    "        if k == 100:\n",
    "            export_landmark(results, '2')\n",
    "            \n",
    "        cv2.imshow('Raw Webcam feed', image)\n",
    "        \n",
    "       # cv2.imshow('Mediapipe Feed', image)        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2623aaa4-8ff0-4480-8652-f24ab1a3925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4989324-8aad-4e30-8524-a65fff95ecd3",
   "metadata": {},
   "source": [
    "Training the Custom Model Using Scikit Learn\n",
    "3.1 Read in Collected Data and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52b6b055-55ac-44f1-9cb6-a437de28676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04f30d8b-702c-4805-b754-9d99eaeef523",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('coords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f88e8a2d-4866-4989-9904-fa2ec1a85ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f071f2c7-2974-4411-a79e-a7d3f306ea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c040a404-182a-454a-ab92-3785293a84e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['class'] == '1.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80ff7966-a395-4028-b417-6462180f75c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67824c26-b951-486e-bc63-2d364f5a4d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_split is a function from the sklearn.model_selection module that is used to\n",
    "# split arrays or matrices into random train and test subsets.\n",
    "\n",
    "#class is my target variable and I want to predict that\n",
    "\n",
    "#X is the dataset with no class coulmn\n",
    "#y extracts the targer variable class\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79e7975a-a3c2-4102-96a4-bd05e0043af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f707608c-5e56-4455-ba2b-a183f187e74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad16e56a-3c1b-43fd-9a31-67fa16bc336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2f0f8d3-7a64-4a40-9ca9-2687d2645381",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    #StandardScaler() before the Random Forest Classifier. \n",
    "    # The StandardScaler standardizes features by removing the mean and scaling to unit variance. \n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab9f49eb-e3c6-4f9e-8f2c-12e783397539",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cc7c089-18dd-470c-9cdf-a529ded3f61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models = {} #create empty dictionary\n",
    "for algorithm, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    fit_models[algorithm] = model #put the results of trained (fitted) models in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69f62c1a-5847-4ef1-a143-b1ab983cb209",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models['rf'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5391446-3d34-4755-b0e1-5c265240117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models['rf'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25337522-44c9-43b5-b401-8e19c18e2cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models['lr'].predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061a2aed-f992-4128-8edc-7ae724bb07f5",
   "metadata": {},
   "source": [
    "We just used the pipeline to train different models on X_train and y_train and store the collected trainer models in fit_models\n",
    "\n",
    "Next step:\n",
    "Evaluate and serialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f80088ca-b676-4a86-923c-908243012e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score #accuracy metrics\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39ac4f6d-1192-46d0-9daf-67b6987d8436",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d2eb0cb-b26f-4eb0-bf03-3a3a3e99aaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for algorithm, model in fit_models.items():\n",
    "    yhat = model.predict(X_test)\n",
    "    print(algorithm, accuracy_score(y_test.values, yhat),\n",
    "          precision_score(y_test.values, yhat, average=\"binary\", pos_label=1),\n",
    "          recall_score(y_test.values, yhat, average=\"binary\", pos_label=2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6bf9aa0-c1e8-46ba-a285-4f3d4e655170",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = fit_models['rf'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ca10115-eb81-4054-881b-4a8725a3d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat[:10]\n",
    "\n",
    "#slicing yhat to display the first 10 elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b06b1ce-c2f1-4b76-bec4-0a3bd1d8ffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('squats.pkl', 'wb') as f:\n",
    "    pickle.dump(fit_models['rf'], f)\n",
    "\n",
    "#'squats.pkl' contains the serialized (pickled) \n",
    "# version of the trained Random Forest classifier (fit_models['rf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59be3da4-d229-4b5e-bf18-802974cd2af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3fa7670-5a32-4dd3-8606-1e555941c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#video feed\n",
    "cap = cv2.VideoCapture('squats.mp4') #this number is the number of my web cam\n",
    "\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "#videoWriter = cv2.VideoWriter('press2.avi', cv2.VideoWriter_fourcc(*'XVID'), fps, (int(width), int(height)))\n",
    "current_stage = ''\n",
    "counter = 0\n",
    "stage = ''\n",
    "feedback = 'he'\n",
    "\n",
    "#setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read() \n",
    "        # detect stuff and render\n",
    "        # print(landmarks)\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) \n",
    "        image.flags.writeable = False #save a bunch of memory\n",
    "\n",
    "        #make detections from the pose\n",
    "        results = pose.process(image) #by processing it, we get our detections back\n",
    "    \n",
    "        #back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        try: \n",
    "            row = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]). flatten()\n",
    "            X = pd.DataFrame([row], columns=landmarks[1:])\n",
    "            body_language_class = model.predict(X)[0]\n",
    "            body_language_prob = model.predict_proba(X)[0]\n",
    "            print(body_language_class, body_language_prob)\n",
    "\n",
    "            #up is class 1; down is class 2\n",
    "\n",
    "            if body_language_class == 1 and body_language_prob[body_language_prob.argmax()] >= .7:\n",
    "                current_stage = 'down'\n",
    "            elif current_stage == 'down' and body_language_class == 2 and body_language_prob[body_language_prob.argmax()] >= .7:\n",
    "                current_stage = 'up'\n",
    "                counter += 1\n",
    "\n",
    "            if body_language_class == 1:\n",
    "                stage = \"up\"\n",
    "            elif body_language_class == 2:\n",
    "                stage = \"down\"\n",
    "\n",
    "            # Drawing rectangles and text on the image\n",
    "            cv2.rectangle(image, (0,0), (400,60), (245,117,16), -1)\n",
    "            \n",
    "            # Drawing predicted class\n",
    "            cv2.putText(image, \"CLASS\", (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(stage), (90,40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Drawing predicted probability\n",
    "            cv2.putText(image, \"PROB\", (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(round(body_language_prob[np.argmax(body_language_prob)],2)), (10,40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Drawing counter\n",
    "            cv2.putText(image, \"COUNTER\", (180,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(counter), (175,40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "\n",
    "    \n",
    "        cv2.imshow('Mediapipe Feed', image)        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "videoWriter.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0d1592-961e-4b34-8f7b-b434fbe90293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea89dd99-f4d9-432f-bc8a-be8006376700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce326842-c6dd-43ed-8d91-ff386b54888b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
