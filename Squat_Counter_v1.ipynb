{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1b03255-b12c-4f77-a08b-515159291ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (0.10.21)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (4.11.0.86)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (from mediapipe) (25.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (from mediapipe) (25.2.10)\n",
      "Requirement already satisfied: jax in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (from mediapipe) (0.5.2)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (from mediapipe) (0.5.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (from mediapipe) (3.10.1)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (from mediapipe) (1.26.4)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (from mediapipe) (4.11.0.86)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (from mediapipe) (4.25.6)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (from mediapipe) (0.5.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (from mediapipe) (0.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: ml_dtypes>=0.4.0 in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (from jax->mediapipe) (0.5.1)\n",
      "Requirement already satisfied: opt_einsum in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (from matplotlib->mediapipe) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (from matplotlib->mediapipe) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (from matplotlib->mediapipe) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (from matplotlib->mediapipe) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (from matplotlib->mediapipe) (3.2.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\miniconda3\\envs\\cv_env\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Using cached pandas-2.2.3-cp310-cp310-win_amd64.whl (11.6 MB)\n",
      "Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   --------------------------- ------------ 7.6/11.1 MB 36.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 38.7 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, threadpoolctl, joblib, scikit-learn, pandas\n",
      "Successfully installed joblib-1.4.2 pandas-2.2.3 pytz-2025.1 scikit-learn-1.6.1 threadpoolctl-3.5.0 tzdata-2025.1\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5d0bb15-1f9c-4bfb-b064-2d7900450cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose #this is where we are importing the pre-built pose detection model from mediapipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a817ae6-5241-4ffa-9330-4d4554795302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://editor.analyticsvidhya.com/uploads/77738pose_tracking_full_body_landmarks.png\" style=\"height:300px\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# Define the HTML content with a corrected image URL\n",
    "html_content = '<img src=\"https://editor.analyticsvidhya.com/uploads/77738pose_tracking_full_body_landmarks.png\" style=\"height:300px\">'\n",
    "\n",
    "# Display the HTML content\n",
    "display(HTML(html_content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e41a741-0476-41fe-8b7b-3ae25b8ec9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a488f6bc-c4b2-4c0e-9a33-045e29ceb23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "landmarks = ['class']\n",
    "for val in range(1, 34): #because 33 points\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03c7a2cb-8409-47f1-b9a9-65778a119076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x1',\n",
       " 'y1',\n",
       " 'z1',\n",
       " 'v1',\n",
       " 'x2',\n",
       " 'y2',\n",
       " 'z2',\n",
       " 'v2',\n",
       " 'x3',\n",
       " 'y3',\n",
       " 'z3',\n",
       " 'v3',\n",
       " 'x4',\n",
       " 'y4',\n",
       " 'z4',\n",
       " 'v4',\n",
       " 'x5',\n",
       " 'y5',\n",
       " 'z5',\n",
       " 'v5',\n",
       " 'x6',\n",
       " 'y6',\n",
       " 'z6',\n",
       " 'v6',\n",
       " 'x7',\n",
       " 'y7',\n",
       " 'z7',\n",
       " 'v7',\n",
       " 'x8',\n",
       " 'y8',\n",
       " 'z8',\n",
       " 'v8',\n",
       " 'x9',\n",
       " 'y9',\n",
       " 'z9',\n",
       " 'v9',\n",
       " 'x10',\n",
       " 'y10',\n",
       " 'z10',\n",
       " 'v10',\n",
       " 'x11',\n",
       " 'y11',\n",
       " 'z11',\n",
       " 'v11',\n",
       " 'x12',\n",
       " 'y12',\n",
       " 'z12',\n",
       " 'v12',\n",
       " 'x13',\n",
       " 'y13',\n",
       " 'z13',\n",
       " 'v13',\n",
       " 'x14',\n",
       " 'y14',\n",
       " 'z14',\n",
       " 'v14',\n",
       " 'x15',\n",
       " 'y15',\n",
       " 'z15',\n",
       " 'v15',\n",
       " 'x16',\n",
       " 'y16',\n",
       " 'z16',\n",
       " 'v16',\n",
       " 'x17',\n",
       " 'y17',\n",
       " 'z17',\n",
       " 'v17',\n",
       " 'x18',\n",
       " 'y18',\n",
       " 'z18',\n",
       " 'v18',\n",
       " 'x19',\n",
       " 'y19',\n",
       " 'z19',\n",
       " 'v19',\n",
       " 'x20',\n",
       " 'y20',\n",
       " 'z20',\n",
       " 'v20',\n",
       " 'x21',\n",
       " 'y21',\n",
       " 'z21',\n",
       " 'v21',\n",
       " 'x22',\n",
       " 'y22',\n",
       " 'z22',\n",
       " 'v22',\n",
       " 'x23',\n",
       " 'y23',\n",
       " 'z23',\n",
       " 'v23',\n",
       " 'x24',\n",
       " 'y24',\n",
       " 'z24',\n",
       " 'v24',\n",
       " 'x25',\n",
       " 'y25',\n",
       " 'z25',\n",
       " 'v25',\n",
       " 'x26',\n",
       " 'y26',\n",
       " 'z26',\n",
       " 'v26',\n",
       " 'x27',\n",
       " 'y27',\n",
       " 'z27',\n",
       " 'v27',\n",
       " 'x28',\n",
       " 'y28',\n",
       " 'z28',\n",
       " 'v28',\n",
       " 'x29',\n",
       " 'y29',\n",
       " 'z29',\n",
       " 'v29',\n",
       " 'x30',\n",
       " 'y30',\n",
       " 'z30',\n",
       " 'v30',\n",
       " 'x31',\n",
       " 'y31',\n",
       " 'z31',\n",
       " 'v31',\n",
       " 'x32',\n",
       " 'y32',\n",
       " 'z32',\n",
       " 'v32',\n",
       " 'x33',\n",
       " 'y33',\n",
       " 'z33',\n",
       " 'v33']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1d90ae2-7040-4061-aefd-5b9c7fbf9b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coords.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar= '\"', quoting= csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "741204b6-8fa3-4eb2-809e-100f033060dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_landmark(results, action):\n",
    "    try:\n",
    "        keypoints = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten()\n",
    "        keypoints = np.insert(keypoints, 0, action)  # Insert action at the beginning\n",
    "\n",
    "        with open('coords.csv', mode='a', newline='') as f:\n",
    "            csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            csv_writer.writerow(keypoints)\n",
    "    except Exception as e:\n",
    "        print('Error occurred while exporting landmarks:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e5f7d46-a5d9-4e28-a02b-5e359a4a310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Video feed\n",
    "cap = cv2.VideoCapture('training_data.mp4')  # Load video file\n",
    "\n",
    "# Setup Mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # Stop if the video ends\n",
    "\n",
    "        # Convert to RGB for Mediapipe processing\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False  # Save memory\n",
    "\n",
    "        # Process image to detect pose\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Convert back to BGR for OpenCV display\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Draw pose landmarks\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Display the video\n",
    "        cv2.imshow('Pose Detection', image)\n",
    "\n",
    "        # Capture keypress\n",
    "        k = cv2.waitKey(1)\n",
    "        if k == 117:  # Key 'u' for saving landmark type '1'\n",
    "            export_landmark(results, '1')\n",
    "        if k == 100:  # Key 'd' for saving landmark type '2'\n",
    "            export_landmark(results, '2')\n",
    "\n",
    "        # Exit on 'q' key\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "77d1f672-86d6-416d-b9a5-ad855ac4e8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a548fe6d-745a-4236-8218-24dbd365e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('coords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55492adf-6f5d-4344-a9f1-29c269b9de61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z31</th>\n",
       "      <th>v31</th>\n",
       "      <th>x32</th>\n",
       "      <th>y32</th>\n",
       "      <th>z32</th>\n",
       "      <th>v32</th>\n",
       "      <th>x33</th>\n",
       "      <th>y33</th>\n",
       "      <th>z33</th>\n",
       "      <th>v33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.625842</td>\n",
       "      <td>0.382540</td>\n",
       "      <td>-0.278379</td>\n",
       "      <td>0.998219</td>\n",
       "      <td>0.626301</td>\n",
       "      <td>0.367036</td>\n",
       "      <td>-0.267018</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>0.626316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112289</td>\n",
       "      <td>0.969579</td>\n",
       "      <td>0.556666</td>\n",
       "      <td>0.784352</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.689475</td>\n",
       "      <td>0.557305</td>\n",
       "      <td>0.844543</td>\n",
       "      <td>0.089445</td>\n",
       "      <td>0.934783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663273</td>\n",
       "      <td>0.500832</td>\n",
       "      <td>-0.298777</td>\n",
       "      <td>0.999510</td>\n",
       "      <td>0.659862</td>\n",
       "      <td>0.487401</td>\n",
       "      <td>-0.282720</td>\n",
       "      <td>0.999593</td>\n",
       "      <td>0.658988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088629</td>\n",
       "      <td>0.956687</td>\n",
       "      <td>0.550015</td>\n",
       "      <td>0.786992</td>\n",
       "      <td>0.625923</td>\n",
       "      <td>0.616155</td>\n",
       "      <td>0.538087</td>\n",
       "      <td>0.860871</td>\n",
       "      <td>0.117298</td>\n",
       "      <td>0.962428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.431886</td>\n",
       "      <td>0.370497</td>\n",
       "      <td>-0.129702</td>\n",
       "      <td>0.999678</td>\n",
       "      <td>0.413210</td>\n",
       "      <td>0.360921</td>\n",
       "      <td>-0.106775</td>\n",
       "      <td>0.999546</td>\n",
       "      <td>0.412733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020689</td>\n",
       "      <td>0.963287</td>\n",
       "      <td>0.481684</td>\n",
       "      <td>0.908725</td>\n",
       "      <td>0.482452</td>\n",
       "      <td>0.797194</td>\n",
       "      <td>0.442401</td>\n",
       "      <td>0.987611</td>\n",
       "      <td>-0.159918</td>\n",
       "      <td>0.954868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.450770</td>\n",
       "      <td>0.374052</td>\n",
       "      <td>-0.113100</td>\n",
       "      <td>0.999725</td>\n",
       "      <td>0.434039</td>\n",
       "      <td>0.364901</td>\n",
       "      <td>-0.093964</td>\n",
       "      <td>0.999608</td>\n",
       "      <td>0.433274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055226</td>\n",
       "      <td>0.961285</td>\n",
       "      <td>0.475380</td>\n",
       "      <td>0.913568</td>\n",
       "      <td>0.446953</td>\n",
       "      <td>0.816030</td>\n",
       "      <td>0.439364</td>\n",
       "      <td>0.984781</td>\n",
       "      <td>-0.117380</td>\n",
       "      <td>0.953458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.660806</td>\n",
       "      <td>0.499839</td>\n",
       "      <td>-0.335329</td>\n",
       "      <td>0.999325</td>\n",
       "      <td>0.657824</td>\n",
       "      <td>0.485978</td>\n",
       "      <td>-0.323548</td>\n",
       "      <td>0.999430</td>\n",
       "      <td>0.657278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138320</td>\n",
       "      <td>0.959791</td>\n",
       "      <td>0.551115</td>\n",
       "      <td>0.782549</td>\n",
       "      <td>0.714453</td>\n",
       "      <td>0.626996</td>\n",
       "      <td>0.537588</td>\n",
       "      <td>0.858446</td>\n",
       "      <td>0.150409</td>\n",
       "      <td>0.961965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class        x1        y1        z1        v1        x2        y2  \\\n",
       "0    1.0  0.625842  0.382540 -0.278379  0.998219  0.626301  0.367036   \n",
       "1    1.0  0.663273  0.500832 -0.298777  0.999510  0.659862  0.487401   \n",
       "2    1.0  0.431886  0.370497 -0.129702  0.999678  0.413210  0.360921   \n",
       "3    1.0  0.450770  0.374052 -0.113100  0.999725  0.434039  0.364901   \n",
       "4    1.0  0.660806  0.499839 -0.335329  0.999325  0.657824  0.485978   \n",
       "\n",
       "         z2        v2        x3  ...       z31       v31       x32       y32  \\\n",
       "0 -0.267018  0.998421  0.626316  ...  0.112289  0.969579  0.556666  0.784352   \n",
       "1 -0.282720  0.999593  0.658988  ...  0.088629  0.956687  0.550015  0.786992   \n",
       "2 -0.106775  0.999546  0.412733  ...  0.020689  0.963287  0.481684  0.908725   \n",
       "3 -0.093964  0.999608  0.433274  ...  0.055226  0.961285  0.475380  0.913568   \n",
       "4 -0.323548  0.999430  0.657278  ...  0.138320  0.959791  0.551115  0.782549   \n",
       "\n",
       "        z32       v32       x33       y33       z33       v33  \n",
       "0  0.625289  0.689475  0.557305  0.844543  0.089445  0.934783  \n",
       "1  0.625923  0.616155  0.538087  0.860871  0.117298  0.962428  \n",
       "2  0.482452  0.797194  0.442401  0.987611 -0.159918  0.954868  \n",
       "3  0.446953  0.816030  0.439364  0.984781 -0.117380  0.953458  \n",
       "4  0.714453  0.626996  0.537588  0.858446  0.150409  0.961965  \n",
       "\n",
       "[5 rows x 133 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "919a14ae-0770-49d8-a635-4da8bd3c4d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 65\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"coords.csv\")\n",
    "\n",
    "# Get the total number of rows\n",
    "num_rows = len(df)\n",
    "\n",
    "print(f\"Total number of rows: {num_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71576243-43b1-42f1-9839-56a7c7482ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Rep Count: 1\n",
      "✅ Rep Count: 2\n",
      "✅ Rep Count: 3\n",
      "✅ Rep Count: 4\n",
      "✅ Rep Count: 5\n",
      "✅ Rep Count: 6\n",
      "✅ Rep Count: 7\n",
      "✅ Rep Count: 8\n",
      "✅ Rep Count: 9\n",
      "✅ Rep Count: 10\n",
      "✅ Rep Count: 11\n",
      "✅ Rep Count: 12\n",
      "✅ Rep Count: 13\n",
      "✅ Rep Count: 14\n",
      "✅ Rep Count: 15\n",
      "✅ Rep Count: 16\n",
      "✅ Rep Count: 17\n",
      "✅ Rep Count: 18\n",
      "✅ Rep Count: 19\n",
      "✅ Rep Count: 20\n",
      "✅ Rep Count: 21\n",
      "✅ Rep Count: 22\n",
      "✅ Rep Count: 23\n",
      "✅ Rep Count: 24\n",
      "✅ Rep Count: 25\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Mediapipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to calculate angle between three points\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)  # First point\n",
    "    b = np.array(b)  # Middle point (joint)\n",
    "    c = np.array(c)  # Last point\n",
    "\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "\n",
    "    return angle\n",
    "\n",
    "# Track reps and squat state\n",
    "rep_count = 0\n",
    "squat_state = \"UP\"  # Start in UP position\n",
    "\n",
    "# Load Video\n",
    "cap = cv2.VideoCapture('training_data.mp4')\n",
    "\n",
    "# Start Pose Detection\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # Stop if the video ends\n",
    "\n",
    "        # Convert to RGB for Mediapipe processing\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False  # Save memory\n",
    "\n",
    "        # Process image to detect pose\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Convert back to BGR for OpenCV display\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            h, w, _ = image.shape  # Get frame dimensions\n",
    "\n",
    "            # Get coordinates of relevant joints\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP].x * w,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_HIP].y * h]\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE].x * w,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y * h]\n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].x * w,\n",
    "                          landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].y * h]\n",
    "\n",
    "            # ✅ Calculate knee angle for rep counting\n",
    "            knee_angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "\n",
    "            # ✅ Rep Counting Using Knee Angle\n",
    "            if knee_angle > 160:  # Standing position (UP)\n",
    "                squat_state = \"UP\"\n",
    "            elif knee_angle < 90:  # Deep squat position (DOWN)\n",
    "                if squat_state == \"UP\":  # If moving from UP → DOWN, count rep\n",
    "                    rep_count += 1\n",
    "                    print(f\"✅ Rep Count: {rep_count}\")\n",
    "                squat_state = \"DOWN\"\n",
    "\n",
    "            # ✅ Draw pose landmarks\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "            # ✅ Display knee angle at knee position\n",
    "            knee_x, knee_y = int(left_knee[0]), int(left_knee[1])\n",
    "            cv2.putText(image, f\"{int(knee_angle)}°\", (knee_x, knee_y), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # ✅ Display Rep Counter in the Corner\n",
    "            cv2.rectangle(image, (0, 0), (200, 60), (245, 117, 16), -1)\n",
    "            cv2.putText(image, f\"Reps: {rep_count}\", (10, 40), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Display the video\n",
    "        cv2.imshow('Squat Counter', image)\n",
    "\n",
    "        # Exit on 'q' key\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b330e1f7-076d-49fe-8df4-f9da89e923b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Rep Count: 1\n",
      "✅ Rep Count: 2\n",
      "✅ Rep Count: 3\n",
      "✅ Rep Count: 4\n",
      "✅ Rep Count: 5\n",
      "✅ Rep Count: 6\n",
      "✅ Rep Count: 7\n",
      "✅ Rep Count: 8\n",
      "✅ Rep Count: 9\n",
      "✅ Rep Count: 10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# Save memory\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Process image to detect pose\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpose\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Convert back to BGR for OpenCV display\u001b[39;00m\n\u001b[0;32m     47\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\cv_env\\lib\\site-packages\\mediapipe\\python\\solutions\\pose.py:185\u001b[0m, in \u001b[0;36mPose.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[0;32m    165\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the pose landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\cv_env\\lib\\site-packages\\mediapipe\\python\\solution_base.py:340\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    334\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    336\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[0;32m    337\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    338\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Mediapipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to calculate angle between three points\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)  # First point\n",
    "    b = np.array(b)  # Middle point (joint)\n",
    "    c = np.array(c)  # Last point\n",
    "\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "\n",
    "    return angle\n",
    "\n",
    "# Track reps and squat state\n",
    "rep_count = 0\n",
    "squat_state = \"UP\"  # Start in UP position\n",
    "feedback = \"\"  # Form feedback\n",
    "feedback_good_bad = \"good\"  # \"good\" or \"bad\"\n",
    "\n",
    "# Load Video\n",
    "cap = cv2.VideoCapture('training_data.mp4')\n",
    "\n",
    "# Start Pose Detection\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # Stop if the video ends\n",
    "\n",
    "        # Convert to RGB for Mediapipe processing\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False  # Save memory\n",
    "\n",
    "        # Process image to detect pose\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Convert back to BGR for OpenCV display\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            h, w, _ = image.shape  # Get frame dimensions\n",
    "\n",
    "            # Get coordinates of relevant joints\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST].x * w,\n",
    "                          landmarks[mp_pose.PoseLandmark.LEFT_WRIST].y * h]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP].x * w,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_HIP].y * h]\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE].x * w,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y * h]\n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].x * w,\n",
    "                          landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].y * h]\n",
    "\n",
    "            # ✅ Calculate angles for feedback\n",
    "            angle_hip_knee = calculate_angle(left_wrist, left_hip, left_knee)\n",
    "            angle_knee_ankle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "            angle_diff = angle_hip_knee - angle_knee_ankle\n",
    "\n",
    "            # ✅ Form Feedback Logic\n",
    "            if angle_knee_ankle < 80:  # Deep squat position\n",
    "                if angle_diff < -10:\n",
    "                    feedback = \"Keep Chest Up\"\n",
    "                    feedback_good_bad = \"bad\"\n",
    "                else:\n",
    "                    feedback = \"Good Form\"\n",
    "                    feedback_good_bad = \"good\"\n",
    "            else:\n",
    "                feedback = \"\"\n",
    "\n",
    "            # ✅ Rep Counting Using Knee Angle\n",
    "            if angle_knee_ankle > 160:  # Standing position (UP)\n",
    "                squat_state = \"UP\"\n",
    "            elif angle_knee_ankle < 90:  # Deep squat position (DOWN)\n",
    "                if squat_state == \"UP\":  # If moving from UP → DOWN, count rep\n",
    "                    rep_count += 1\n",
    "                    print(f\"✅ Rep Count: {rep_count}\")\n",
    "                squat_state = \"DOWN\"\n",
    "\n",
    "            # ✅ Draw pose landmarks\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "            # ✅ Display knee angle at knee position\n",
    "            knee_x, knee_y = int(left_knee[0]), int(left_knee[1])\n",
    "            cv2.putText(image, f\"{int(angle_knee_ankle)}°\", (knee_x, knee_y), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # ✅ Display Form Feedback & Rep Counter\n",
    "            cv2.rectangle(image, (0, 0), (300, 100), (245, 117, 16), -1)  # Background\n",
    "\n",
    "            cv2.putText(image, f\"Reps: {rep_count}\", (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            cv2.putText(image, f\"Feedback: {feedback}\", (10, 60), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0) if feedback_good_bad == \"good\" else (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            cv2.putText(image, f\"Form: {feedback_good_bad}\", (10, 90), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0) if feedback_good_bad == \"good\" else (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Display the video\n",
    "        cv2.imshow('Squat Counter & Form Feedback', image)\n",
    "\n",
    "        # Exit on 'q' key\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a109bac6-4925-4be6-a097-33161d5d4c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d736642-3ccf-438b-ac46-c7fef57bbc14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68141b76-b31d-4159-a4ca-7c459d4401b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
